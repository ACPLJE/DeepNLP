# DistilBERT model configuration
type: "distilbert"
model_name: "distilbert-base-uncased"
hidden_size: 768
num_attention_heads: 12
num_hidden_layers: 6
intermediate_size: 3072
hidden_dropout_prob: 0.1
attention_probs_dropout_prob: 0.1
max_position_embeddings: 512
initializer_range: 0.02
layer_norm_eps: 1e-12

# Distillation specific settings
temperature: 2.0
alpha_ce: 0.5
alpha_mlm: 0.0
alpha_cos: 0.5