# configs/base_config.yaml
training:
  epochs: 10
  batch_size: 32
  learning_rate: 0.00002
  warmup_steps: 500
  max_grad_norm: 1.0
  logging_steps: 100
  eval_steps: 1000
  save_steps: 2000
  show_progress_bar: true
  weight_decay: 0.01
  # Distillation specific parameters
  temperature: 2.0
  qa_loss_weight: 1.0
  token_context_weight: 0.5
  sequence_context_weight: 0.5
  
model:
  hidden_size: 768
  dropout_rate: 0.1